"""
ğŸ§€ ä¹³é…ªã®BTCé æ¸¬å®¤ â€” è‡ªå‹•æ ¡æº–æ’ç¨‹å·¥å…·
=====================================================

è¨­è¨ˆçµ¦ VPS ä¸Šçš„ Agent / crontab ä½¿ç”¨ã€‚
æ¯æ—¥è‡ªå‹•åŸ·è¡Œä»¥ä¸‹æµç¨‹:
    1. å¾ Binance ä¸‹è¼‰æœ€æ–° 16 å°æ™‚çœŸå¯¦ K ç·š
    2. ä½¿ç”¨æ ¡æº–å¼•æ“æœç´¢æœ€ä½³æ¬Šé‡
    3. èˆ‡ç¾æœ‰æ¬Šé‡æ¯”è¼ƒ
    4. è‹¥æ–°æ¬Šé‡é¡¯è‘—å„ªæ–¼èˆŠæ¬Šé‡ â†’ è‡ªå‹•æ›´æ–° config.py
    5. è¨˜éŒ„æ ¡æº–æ­·å²ï¼Œä¾› AI åˆ†æè¶¨å‹¢

VPS å®šæ™‚ä»»å‹™è¨­å®š:
    # æ¯æ—¥å‡Œæ™¨ 4:00 è‡ªå‹•æ ¡æº–ï¼ˆUTC+8ï¼‰
    0 4 * * * cd /path/to/backend && python tools/auto_calibrate.py >> logs/calibrate.log 2>&1

    # æˆ–æ¯ 8 å°æ™‚æ ¡æº–ä¸€æ¬¡ï¼ˆæ›´ç©æ¥µçš„è‡ªé©æ‡‰ï¼‰
    0 */8 * * * cd /path/to/backend && python tools/auto_calibrate.py >> logs/calibrate.log 2>&1

ä½¿ç”¨æ–¹å¼:
    python tools/auto_calibrate.py                   # é è¨­è‡ªå‹•æ ¡æº–
    python tools/auto_calibrate.py --dry-run          # åªæ¸¬è©¦ï¼Œä¸å¯«å…¥
    python tools/auto_calibrate.py --threshold 0.15   # æ”¹å–„ 15% æ‰æ›´æ–°
    python tools/auto_calibrate.py --notify            # æ ¡æº–å¾Œç™¼é€é€šçŸ¥
"""

import sys
import os
import json
import time
import logging
import math
from datetime import datetime
from pathlib import Path

# â”€â”€ åŠ å…¥å°ˆæ¡ˆè·¯å¾‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app import config

# â”€â”€ æ—¥èªŒè¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
LOG_DIR = Path(__file__).parent.parent / "logs"
LOG_DIR.mkdir(exist_ok=True)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)-7s | %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(LOG_DIR / "auto_calibrate.log", encoding="utf-8"),
    ],
)
logger = logging.getLogger("auto_calibrate")

# â”€â”€ æ ¡æº–æ­·å²è¨˜éŒ„è·¯å¾‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
HISTORY_DIR = Path(__file__).parent.parent / "data" / "calibration_history"
HISTORY_DIR.mkdir(parents=True, exist_ok=True)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# å¸‚å ´ç‹€æ…‹åµæ¸¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def detect_market_regime(klines: list) -> dict:
    """
    åŸºæ–¼æœ€è¿‘çš„ K ç·šæ•¸æ“šåµæ¸¬å¸‚å ´ç‹€æ…‹

    Returns:
        {
            "regime": "strong_trend" | "mild_trend" | "ranging" | "choppy" | "crash",
            "volatility_pct": float,
            "trend_strength": float,
            "recommended_mode": str,
            "details": str,
        }
    """
    if len(klines) < 30:
        return {
            "regime": "ranging",
            "volatility_pct": 0,
            "trend_strength": 0,
            "recommended_mode": "balanced",
            "details": "æ•¸æ“šä¸è¶³ï¼Œä½¿ç”¨é è¨­æ¨¡å¼",
        }

    regime_cfg = config.MARKET_REGIME_CONFIG

    # â”€â”€ è¨ˆç®—æ³¢å‹•ç‡ (ATR-like) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ä½¿ç”¨æœ€è¿‘ 30 æ ¹ K ç·šçš„ (high-low)/close ç™¾åˆ†æ¯”
    recent = klines[-30:]
    tr_list = []
    for i, k in enumerate(recent):
        high = k.get("h", k.get("c", 0))
        low = k.get("l", k.get("c", 0))
        close = k.get("c", 1)
        tr = (high - low) / close * 100 if close > 0 else 0
        tr_list.append(tr)

    avg_tr = sum(tr_list) / len(tr_list) if tr_list else 0

    # â”€â”€ è¨ˆç®—è¶¨å‹¢å¼·åº¦ (é¡ ADX) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ä½¿ç”¨åƒ¹æ ¼æ–¹å‘è®ŠåŒ–çš„ä¸€è‡´æ€§ä¾†æ¨¡æ“¬ ADX
    closes = [k.get("c", 0) for k in recent]
    directions = []
    for i in range(1, len(closes)):
        if closes[i] > closes[i-1]:
            directions.append(1)
        elif closes[i] < closes[i-1]:
            directions.append(-1)
        else:
            directions.append(0)

    if directions:
        # æ–¹å‘ä¸€è‡´æ€§ = |å¹³å‡æ–¹å‘| * 100
        avg_dir = sum(directions) / len(directions)
        trend_strength = abs(avg_dir) * 50  # 0~50 çš„ç¯„åœ

        # åŠ ä¸Šæ•´é«”åƒ¹æ ¼è®Šå‹•å¹…åº¦
        total_change_pct = abs(closes[-1] - closes[0]) / closes[0] * 100 if closes[0] > 0 else 0
        trend_strength += total_change_pct * 5  # æ”¾å¤§è¶¨å‹¢æ•ˆæœ
    else:
        trend_strength = 0

    # â”€â”€ åˆ¤å®šå¸‚å ´ç‹€æ…‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    regime = "ranging"
    details = ""

    if avg_tr > regime_cfg["volatility_high"]:
        # é«˜æ³¢å‹•
        if trend_strength > regime_cfg["trend_strong"]:
            regime = "strong_trend"
            details = f"é«˜æ³¢å‹•+å¼·è¶¨å‹¢ï¼ˆvolatility={avg_tr:.2f}%, trend={trend_strength:.1f}ï¼‰"
        else:
            regime = "choppy"
            details = f"é«˜æ³¢å‹•+ç„¡è¶¨å‹¢ï¼ˆvolatility={avg_tr:.2f}%, trend={trend_strength:.1f}ï¼‰"
    elif avg_tr > regime_cfg["volatility_low"]:
        # ä¸­æ³¢å‹•
        if trend_strength > regime_cfg["trend_mild"]:
            regime = "mild_trend"
            details = f"ä¸­æ³¢å‹•+æº«å’Œè¶¨å‹¢ï¼ˆvolatility={avg_tr:.2f}%, trend={trend_strength:.1f}ï¼‰"
        else:
            regime = "ranging"
            details = f"ä¸­æ³¢å‹•+ç›¤æ•´ï¼ˆvolatility={avg_tr:.2f}%, trend={trend_strength:.1f}ï¼‰"
    else:
        # ä½æ³¢å‹•
        regime = "ranging"
        details = f"ä½æ³¢å‹•+ç›¤æ•´ï¼ˆvolatility={avg_tr:.2f}%, trend={trend_strength:.1f}ï¼‰"

    # æª¢æŸ¥æ˜¯å¦å´©ç›¤ï¼ˆæœ€è¿‘ 30 åˆ†é˜è·Œå¹… > 2%ï¼‰
    if len(closes) >= 30:
        last_30_change = (closes[-1] - closes[-30]) / closes[-30] * 100 if closes[-30] > 0 else 0
        if last_30_change < -2.0:
            regime = "crash"
            details = f"âš ï¸ å´©ç›¤åµæ¸¬ï¼30 åˆ†é˜è·Œå¹… {last_30_change:.2f}%"

    recommended_mode = regime_cfg["regime_mode_map"].get(regime, "balanced")

    return {
        "regime": regime,
        "volatility_pct": round(avg_tr, 4),
        "trend_strength": round(trend_strength, 2),
        "recommended_mode": recommended_mode,
        "details": details,
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# è‡ªå‹•æ ¡æº–ä¸»æµç¨‹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_auto_calibration(
    dry_run: bool = False,
    improvement_threshold: float = 0.10,
    random_iterations: int = 150,
    hill_iterations: int = 80,
    notify: bool = False,
):
    """
    è‡ªå‹•æ ¡æº–å®Œæ•´æµç¨‹

    Args:
        dry_run: åªæ¸¬è©¦ï¼Œä¸å¯«å…¥ config.py
        improvement_threshold: æ–°æ¬Šé‡éœ€æ¯”èˆŠæ¬Šé‡æ”¹å–„ N% æ‰æ›´æ–°
        random_iterations: Random Search è¿­ä»£æ¬¡æ•¸
        hill_iterations: Hill Climbing è¿­ä»£æ¬¡æ•¸
        notify: æ ¡æº–å®Œæˆå¾Œæ˜¯å¦ç™¼é€é€šçŸ¥
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    logger.info("=" * 60)
    logger.info(f"ğŸ§€ è‡ªå‹•æ ¡æº–é–‹å§‹ @ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 60)

    # â”€â”€ Step 1: ä¸‹è¼‰çœŸå¯¦æ•¸æ“š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info("\nğŸ“¥ Step 1: ä¸‹è¼‰æœ€æ–°å¸‚å ´æ•¸æ“š...")
    from tools.fetch_historical_data import (
        fetch_binance_klines,
        clear_snapshots,
        generate_snapshots_from_real_data,
    )

    # å…ˆä¸‹è¼‰ K ç·šï¼ˆç”¨æ–¼å¸‚å ´ç‹€æ…‹åµæ¸¬ï¼‰
    raw_klines = fetch_binance_klines(limit=1000)
    if not raw_klines:
        logger.error("âŒ ç„¡æ³•ç²å– Binance æ•¸æ“šï¼Œæ ¡æº–ä¸­æ­¢ã€‚")
        return False

    logger.info(f"   ç²å– {len(raw_klines)} æ ¹ K ç·š")
    logger.info(f"   åƒ¹æ ¼ç¯„åœ: ${min(k['l'] for k in raw_klines):,.2f} - ${max(k['h'] for k in raw_klines):,.2f}")

    # â”€â”€ Step 2: åµæ¸¬å¸‚å ´ç‹€æ…‹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info("\nğŸ” Step 2: åµæ¸¬å¸‚å ´ç‹€æ…‹...")
    regime = detect_market_regime(raw_klines)
    logger.info(f"   ç‹€æ…‹: {regime['regime']}")
    logger.info(f"   æ³¢å‹•ç‡: {regime['volatility_pct']:.4f}%")
    logger.info(f"   è¶¨å‹¢å¼·åº¦: {regime['trend_strength']:.2f}")
    logger.info(f"   æ¨è–¦æ¨¡å¼: {regime['recommended_mode']}")
    logger.info(f"   è©³æƒ…: {regime['details']}")

    calibration_mode = regime["recommended_mode"]

    # â”€â”€ Step 3: æ¸…ç©ºèˆŠå¿«ç…§ï¼Œå¯«å…¥æ–°æ•¸æ“š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info("\nğŸ—‘ï¸  Step 3: æ›´æ–°å¿«ç…§æ•¸æ“š...")
    clear_snapshots()
    generate_snapshots_from_real_data(hours=16)

    # â”€â”€ Step 4: åŸ·è¡Œæ ¡æº– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info(f"\nâš™ï¸  Step 4: åŸ·è¡Œæ¬Šé‡æ ¡æº–ï¼ˆæ¨¡å¼: {calibration_mode}ï¼‰...")
    from tools.calibrate_weights import WeightCalibrator, save_results_json

    calibrator = WeightCalibrator(
        trading_mode=calibration_mode,
        initial_balance=1000.0,
        snapshot_limit=5000,
        use_fees=True,
    )

    best = calibrator.run_calibration(
        random_iterations=random_iterations,
        hill_climb_iterations=hill_iterations,
        top_k=5,
    )

    # â”€â”€ Step 5: äº¤å‰é©—è­‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info("\nğŸ“Š Step 5: äº¤å‰é©—è­‰...")
    cv_result = calibrator.cross_validate(best.weights, n_folds=3)

    # â”€â”€ Step 6: æ¯”è¼ƒæ–°èˆŠæ¬Šé‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info("\nğŸ“ˆ Step 6: æ¯”è¼ƒæ–°èˆŠæ¬Šé‡...")

    # æ‰¾åˆ° baseline çµæœ
    baseline = next(
        (r for r in calibrator.results if r.source == "baseline"), None
    )

    improvement = 0.0
    if baseline and baseline.composite_score > 0:
        improvement = (best.composite_score - baseline.composite_score) / baseline.composite_score
    elif best.composite_score > 0:
        improvement = 1.0  # baseline ç‚º 0ï¼Œä»»ä½•æ”¹å–„éƒ½æ˜¯ 100%

    logger.info(f"   Baseline Composite: {baseline.composite_score:.4f}" if baseline else "   Baseline: N/A")
    logger.info(f"   æœ€ä½³ Composite: {best.composite_score:.4f}")
    logger.info(f"   æ”¹å–„å¹…åº¦: {improvement:+.1%}")
    logger.info(f"   äº¤å‰é©—è­‰ç©©å®šæ€§: {cv_result['stability_score']:.4f}")

    # â”€â”€ Step 7: æ±ºå®šæ˜¯å¦æ›´æ–° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    should_update = (
        improvement >= improvement_threshold
        and cv_result["stability_score"] > 0.3  # ç©©å®šæ€§è‡³å°‘ 30%
        and best.total_trades >= 5              # è‡³å°‘ 5 ç­†äº¤æ˜“
    )

    logger.info("")
    if should_update:
        logger.info(f"âœ… æ–°æ¬Šé‡é€šéæ›´æ–°æ¢ä»¶:")
        logger.info(f"   âœ“ æ”¹å–„ {improvement:+.1%} â‰¥ é–€æª» {improvement_threshold:+.1%}")
        logger.info(f"   âœ“ ç©©å®šæ€§ {cv_result['stability_score']:.4f} > 0.3")
        logger.info(f"   âœ“ äº¤æ˜“æ•¸ {best.total_trades} â‰¥ 5")
    else:
        reasons = []
        if improvement < improvement_threshold:
            reasons.append(f"æ”¹å–„ä¸è¶³ ({improvement:+.1%} < {improvement_threshold:+.1%})")
        if cv_result["stability_score"] <= 0.3:
            reasons.append(f"ç©©å®šæ€§ä¸è¶³ ({cv_result['stability_score']:.4f} â‰¤ 0.3)")
        if best.total_trades < 5:
            reasons.append(f"äº¤æ˜“æ¬¡æ•¸ä¸è¶³ ({best.total_trades} < 5)")
        logger.info(f"â­ï¸  ä¸æ›´æ–°æ¬Šé‡: {'; '.join(reasons)}")

    # â”€â”€ Step 8: å¯«å…¥æˆ–è·³é â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if should_update and not dry_run:
        from tools.calibrate_weights import apply_weights_to_config
        apply_weights_to_config(best.weights)
        logger.info("ğŸ“ æœ€ä½³æ¬Šé‡å·²è‡ªå‹•å¯«å…¥ config.py")
        updated = True
    elif should_update and dry_run:
        logger.info("ğŸ”¬ [DRY RUN] ä¸å¯¦éš›å¯«å…¥ config.py")
        updated = False
    else:
        updated = False

    # â”€â”€ Step 9: ä¿å­˜æ ¡æº–æ­·å² â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    history_record = {
        "timestamp": datetime.now().isoformat(),
        "market_regime": regime,
        "calibration_mode": calibration_mode,
        "old_weights": dict(config.BIAS_WEIGHTS) if not updated else (
            baseline.weights if baseline else {}
        ),
        "new_weights": best.weights,
        "metrics": {
            "baseline_composite": baseline.composite_score if baseline else 0,
            "best_composite": best.composite_score,
            "improvement_pct": round(improvement * 100, 2),
            "sharpe_ratio": best.sharpe_ratio,
            "win_rate": best.win_rate,
            "profit_factor": best.profit_factor,
            "total_trades": best.total_trades,
        },
        "cross_validation": cv_result,
        "updated": updated,
        "dry_run": dry_run,
        "total_iterations": len(calibrator.results),
    }

    history_file = HISTORY_DIR / f"calibration_{timestamp}.json"
    with open(history_file, "w", encoding="utf-8") as f:
        json.dump(history_record, f, indent=2, ensure_ascii=False, default=str)

    logger.info(f"ğŸ“ æ ¡æº–æ­·å²å·²å„²å­˜: {history_file}")

    # åŒæ™‚ä¿å­˜å®Œæ•´çµæœ
    full_result_file = HISTORY_DIR / f"full_results_{timestamp}.json"
    save_results_json(calibrator, str(full_result_file))

    # â”€â”€ Step 10: é€šçŸ¥ (å¯é¸) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if notify:
        _send_notification(history_record)

    # â”€â”€ æ‘˜è¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info("")
    logger.info("=" * 60)
    logger.info("ğŸ“‹ è‡ªå‹•æ ¡æº–æ‘˜è¦")
    logger.info("=" * 60)
    logger.info(f"   å¸‚å ´ç‹€æ…‹: {regime['regime']} â†’ ä½¿ç”¨æ¨¡å¼: {calibration_mode}")
    logger.info(f"   è¿­ä»£æ¬¡æ•¸: {len(calibrator.results)}")
    logger.info(f"   æœ€ä½³ Sharpe: {best.sharpe_ratio:.2f}")
    logger.info(f"   æœ€ä½³å‹ç‡: {best.win_rate:.1f}%")
    logger.info(f"   æ”¹å–„å¹…åº¦: {improvement:+.1%}")
    logger.info(f"   æ˜¯å¦æ›´æ–°: {'âœ… å·²æ›´æ–°' if updated else 'âŒ æœªæ›´æ–°'}")
    logger.info("=" * 60)

    return updated


def _send_notification(record: dict):
    """
    ç™¼é€æ ¡æº–çµæœé€šçŸ¥
    
    ç›®å‰æ”¯æ´:
    - å¯«å…¥ JSON æª”æ¡ˆï¼ˆä¾› CRO Dashboard è®€å–ï¼‰
    - æœªä¾†å¯æ“´å±•: Discord Webhook, Telegram, Email
    """
    try:
        # å¯«å…¥è‡³ /data/latest_calibration.json ä¾› Dashboard è®€å–
        latest_file = Path(__file__).parent.parent / "data" / "latest_calibration.json"
        with open(latest_file, "w", encoding="utf-8") as f:
            json.dump({
                "timestamp": record["timestamp"],
                "regime": record["market_regime"]["regime"],
                "mode": record["calibration_mode"],
                "improvement_pct": record["metrics"]["improvement_pct"],
                "sharpe": record["metrics"]["sharpe_ratio"],
                "win_rate": record["metrics"]["win_rate"],
                "updated": record["updated"],
            }, f, indent=2, ensure_ascii=False)
        logger.info("ğŸ”” é€šçŸ¥å·²ç™¼é€è‡³ latest_calibration.json")
    except Exception as e:
        logger.warning(f"âš ï¸ é€šçŸ¥ç™¼é€å¤±æ•—: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ ¡æº–æ­·å²åˆ†æ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_calibration_history():
    """
    åˆ†ææ ¡æº–æ­·å²ï¼Œæ‰¾å‡ºæœ€ç©©å®šçš„æ¬Šé‡è¶¨å‹¢

    ä¾› AI Agent ä½¿ç”¨ï¼Œå¯ä»¥è¾¨èªå‡º:
    - å“ªäº›æŒ‡æ¨™çš„æœ€ä½³æ¬Šé‡æ˜¯ç©©å®šçš„ï¼ˆæ¯æ¬¡æ ¡æº–éƒ½å·®ä¸å¤šï¼‰
    - å“ªäº›æŒ‡æ¨™çš„æœ€ä½³æ¬Šé‡è®Šå‹•å¤§ï¼ˆèˆ‡å¸‚å ´ç‹€æ…‹ç›¸é—œï¼‰
    """
    history_files = sorted(HISTORY_DIR.glob("calibration_*.json"))

    if not history_files:
        logger.info("ğŸ“­ ç„¡æ ¡æº–æ­·å²è¨˜éŒ„")
        return None

    records = []
    for f in history_files:
        with open(f, "r", encoding="utf-8") as fp:
            records.append(json.load(fp))

    # çµ±è¨ˆæ¯å€‹æŒ‡æ¨™çš„æœ€ä½³æ¬Šé‡åˆ†ä½ˆ
    weight_stats = {}
    for key in config.BIAS_WEIGHTS.keys():
        values = [r["new_weights"].get(key, 0) for r in records]
        avg = sum(values) / len(values) if values else 0
        std = math.sqrt(
            sum((v - avg) ** 2 for v in values) / len(values)
        ) if len(values) > 1 else 0

        weight_stats[key] = {
            "avg": round(avg, 2),
            "std": round(std, 2),
            "min": min(values),
            "max": max(values),
            "cv": round(std / avg, 3) if avg > 0 else float("inf"),
            "stable": std < 2.0,  # æ¨™æº–å·® < 2 è¦–ç‚ºç©©å®š
        }

    # æŒ‰ç©©å®šæ€§æ’åº
    stable_keys = [k for k, v in weight_stats.items() if v["stable"]]
    volatile_keys = [k for k, v in weight_stats.items() if not v["stable"]]

    analysis = {
        "total_records": len(records),
        "date_range": {
            "first": records[0]["timestamp"],
            "last": records[-1]["timestamp"],
        },
        "weight_stats": weight_stats,
        "stable_indicators": stable_keys,
        "volatile_indicators": volatile_keys,
        "regime_distribution": {},
        "update_rate": sum(1 for r in records if r.get("updated")) / len(records),
    }

    # çµ±è¨ˆå¸‚å ´ç‹€æ…‹åˆ†ä½ˆ
    for r in records:
        regime = r.get("market_regime", {}).get("regime", "unknown")
        analysis["regime_distribution"][regime] = (
            analysis["regime_distribution"].get(regime, 0) + 1
        )

    logger.info("\nğŸ“Š æ ¡æº–æ­·å²åˆ†æ:")
    logger.info(f"   è¨˜éŒ„æ•¸: {len(records)}")
    logger.info(f"   æ›´æ–°ç‡: {analysis['update_rate']:.1%}")
    logger.info(f"   ç©©å®šæŒ‡æ¨™: {', '.join(stable_keys) or 'ç„¡'}")
    logger.info(f"   è®Šå‹•æŒ‡æ¨™: {', '.join(volatile_keys) or 'ç„¡'}")
    logger.info(f"   å¸‚å ´ç‹€æ…‹åˆ†ä½ˆ: {analysis['regime_distribution']}")

    return analysis


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI å…¥å£
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    import argparse

    parser = argparse.ArgumentParser(
        description="ğŸ§€ ä¹³é…ªã®BTCé æ¸¬å®¤ â€” è‡ªå‹•æ ¡æº–æ’ç¨‹å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  python tools/auto_calibrate.py                    # è‡ªå‹•æ ¡æº–ï¼ˆç¬¦åˆæ¢ä»¶è‡ªå‹•æ›´æ–°ï¼‰
  python tools/auto_calibrate.py --dry-run           # åªæ¸¬è©¦ï¼Œä¸å¯«å…¥
  python tools/auto_calibrate.py --threshold 0.15    # æ”¹å–„ 15% æ‰æ›´æ–°
  python tools/auto_calibrate.py --history           # åˆ†ææ ¡æº–æ­·å²

VPS crontab è¨­å®š:
  0 4 * * * cd /path/to/backend && python tools/auto_calibrate.py >> logs/calibrate.log 2>&1
        """,
    )

    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="åªæ¸¬è©¦ï¼Œä¸å¯«å…¥ config.py",
    )
    parser.add_argument(
        "--threshold",
        type=float,
        default=0.10,
        help="æ”¹å–„é–€æª»ç™¾åˆ†æ¯” (é è¨­: 0.10 = 10%%)",
    )
    parser.add_argument(
        "-n", "--iterations",
        type=int,
        default=150,
        help="Random Search è¿­ä»£æ¬¡æ•¸ (é è¨­: 150)",
    )
    parser.add_argument(
        "--hill",
        type=int,
        default=80,
        help="Hill Climbing è¿­ä»£æ¬¡æ•¸ (é è¨­: 80)",
    )
    parser.add_argument(
        "--notify",
        action="store_true",
        help="æ ¡æº–å®Œæˆå¾Œç™¼é€é€šçŸ¥",
    )
    parser.add_argument(
        "--history",
        action="store_true",
        help="åˆ†ææ ¡æº–æ­·å²ï¼ˆä¸åŸ·è¡Œæ–°çš„æ ¡æº–ï¼‰",
    )

    args = parser.parse_args()

    if args.history:
        analyze_calibration_history()
        return

    run_auto_calibration(
        dry_run=args.dry_run,
        improvement_threshold=args.threshold,
        random_iterations=args.iterations,
        hill_iterations=args.hill,
        notify=args.notify,
    )


if __name__ == "__main__":
    main()
