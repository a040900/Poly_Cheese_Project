"""
ğŸ§€ ä¹³é…ªã®BTCé æ¸¬å®¤ â€” çœŸå¯¦æ­·å²æ•¸æ“šç²å–å·¥å…·
=====================================================

å¾ Binance API ç²å–çœŸå¯¦çš„ BTCUSDT æ­·å² K ç·šæ•¸æ“š (1 åˆ†é˜)ï¼Œ
ä¸¦ç”Ÿæˆ market_snapshots ä¾›å›æ¸¬ä½¿ç”¨ã€‚

åŠŸèƒ½:
    1. ä¸‹è¼‰æœ€è¿‘ N å°æ™‚çš„çœŸå¯¦ K ç·š (OHLCV)
    2. ä½¿ç”¨çœŸå¯¦æ•¸æ“šè¨ˆç®—æŠ€è¡“æŒ‡æ¨™ (EMA, RSI, MACD, BB...)
    3. æ¨¡æ“¬ Polymarket åˆç´„åƒ¹æ ¼ (åŸºæ–¼çœŸå¯¦ BTC æ³¢å‹•)
    4. å¯«å…¥ market_snapshots åˆ°è³‡æ–™åº«

ä½¿ç”¨æ–¹å¼:
    cd backend
    python tools/fetch_historical_data.py --hours 24
"""

import sys
import os
import time
import json
import logging
import random
import requests
from datetime import datetime, timedelta

# â”€â”€ åŠ å…¥å°ˆæ¡ˆè·¯å¾‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.database import db
from app.indicators import technical

# â”€â”€ æ—¥èªŒè¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)-7s | %(message)s",
    datefmt="%H:%M:%S",
)
logger = logging.getLogger("fetcher")

BINANCE_API_URL = "https://api.binance.com/api/v3/klines"

def fetch_binance_klines(symbol="BTCUSDT", interval="1m", limit=1000):
    """å¾ Binance ç²å– K ç·šæ•¸æ“š"""
    params = {
        "symbol": symbol,
        "interval": interval,
        "limit": limit
    }
    try:
        response = requests.get(BINANCE_API_URL, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        # Binance kline format:
        # [Open time, Open, High, Low, Close, Volume, Close time, ...]
        klines = []
        for k in data:
            klines.append({
                "t": k[0] / 1000,
                "o": float(k[1]),
                "h": float(k[2]),
                "l": float(k[3]),
                "c": float(k[4]),
                "v": float(k[5]),
            })
        return klines
    except Exception as e:
        logger.error(f"âŒ ç„¡æ³•ç²å– Binance æ•¸æ“š: {e}")
        return []

def generate_snapshots_from_real_data(hours: int = 24):
    """
    ä½¿ç”¨çœŸå¯¦ K ç·šæ•¸æ“šç”Ÿæˆ market_snapshots
    """
    logger.info(f"ğŸ“¥ å¾ Binance ä¸‹è¼‰æœ€è¿‘ {hours} å°æ™‚ BTC æ•¸æ“š...")
    
    # è¨ˆç®—éœ€è¦å¤šå°‘æ ¹ K ç·š (æ¯åˆ†é˜ä¸€æ ¹)
    limit = min(hours * 60, 1000)  # Binance å–®æ¬¡æœ€å¤š 1000 æ ¹
    # å¦‚æœéœ€è¦æ›´å¤šï¼Œé€™è£¡ç°¡åŒ–è™•ç†åªæŠ“æœ€è¿‘ 1000 åˆ†é˜ (ç´„ 16 å°æ™‚)
    # è‹¥è¦å®Œæ•´ 24h+ï¼Œéœ€åˆ†é è™•ç†ï¼Œä½† 1000 æ ¹è¶³å¤ æ ¡æº– demo
    klines = fetch_binance_klines(limit=limit)

    if not klines:
        logger.error("âŒ ç„¡æ³•ç²å– K ç·šæ•¸æ“šï¼Œçµ‚æ­¢ã€‚")
        return

    logger.info(f"âœ… æˆåŠŸç²å– {len(klines)} æ ¹ K ç·š")
    
    # æº–å‚™å¯«å…¥è³‡æ–™åº«
    snapshots_added = 0
    
    # ç”¨æ–¼è¨ˆç®—æŒ‡æ¨™çš„çª—å£
    window = []

    for i, k in enumerate(klines):
        window.append(k)
        # ä¿æŒçª—å£å¤§å°
        if len(window) > 100:
            window.pop(0)
            
        # è‡³å°‘éœ€è¦ 30 æ ¹ K ç·šæ‰é–‹å§‹è¨ˆç®—æŒ‡æ¨™
        if len(window) < 30:
            continue

        price = k["c"]
        ts = k["t"]

        # 1. è¨ˆç®—çœŸå¯¦æŠ€è¡“æŒ‡æ¨™
        indicators = {
            "ema": {}, "rsi": {}, "macd": {}, "bb": {}, "ha": {}
        }
        
        # EMA
        ema_s, ema_l = technical.ema_cross(window)
        if ema_s and ema_l:
            indicators["ema"] = {"short": ema_s, "long": ema_l}

        # RSI
        rsi_val = technical.rsi(window)
        if rsi_val:
            indicators["rsi"] = {"value": rsi_val}

        # MACD
        m, s, h = technical.macd(window)
        if h is not None:
            indicators["macd"] = {"histogram": h}

        # BB
        bb = technical.bollinger_bands(window)
        if bb:
            indicators["bb"] = bb

        # HA
        streak = technical.ha_streak(window)
        indicators["ha"] = {"streak": streak}

        # 2. æ¨¡æ“¬ Polymarket åƒ¹æ ¼ (åŸºæ–¼çœŸå¯¦æ³¢å‹•)
        # é€™è£¡åªèƒ½æ¨¡æ“¬ï¼Œå› ç‚ºæ²’æœ‰ PM æ­·å²æ•¸æ“š
        # å‡è¨­: è¶¨å‹¢å¼·æ™‚ PM åƒ¹æ ¼æœƒåé›¢ 0.5
        bias = 0.5
        if ema_s and ema_l:
             diff_pct = (ema_s - ema_l) / ema_l * 100
             bias += diff_pct * 2.0  # æ”¾å¤§è¶¨å‹¢å½±éŸ¿
        
        bias = max(0.05, min(0.95, bias))
        pm_up = bias
        pm_down = 1.0 - bias
        
        # åŠ å…¥éš¨æ©Ÿé›œè¨Šæ¨¡æ“¬ Spread
        pm_up += random.gauss(0, 0.01)
        pm_down += random.gauss(0, 0.01)

        # 3. å»ºæ§‹ Snapshot
        snapshot = {
            "timestamp": ts,
            "btc_price": price,
            "pm_up_price": round(pm_up, 4),
            "pm_down_price": round(pm_down, 4),
            "chainlink_price": price, # ç°¡åŒ–
            "bias_score": 0, # è®“å›æ¸¬å¼•æ“è‡ªå·±ç®—
            "signal": "NEUTRAL", # è®“å›æ¸¬å¼•æ“è‡ªå·±ç®—
            "trading_mode": "balanced",
            "indicators": indicators,
        }

        db.save_market_snapshot(snapshot)
        snapshots_added += 1

    logger.info(f"âœ… å·²å°‡ {snapshots_added} ç­†çœŸå¯¦å¸‚å ´å¿«ç…§å¯«å…¥è³‡æ–™åº«")
    logger.info(f"   æ™‚é–“ç¯„åœ: {datetime.fromtimestamp(klines[0]['t'])} -> {datetime.fromtimestamp(klines[-1]['t'])}")
    logger.info(f"   åƒ¹æ ¼ç¯„åœ: ${min(k['l'] for k in klines):,.2f} - ${max(k['h'] for k in klines):,.2f}")

def clear_snapshots():
    """æ¸…ç©º market_snapshots è¡¨"""
    logger.warning("ğŸ—‘ï¸ æ­£åœ¨æ¸…ç©º market_snapshots è¡¨...")
    with db._connect() as conn:
        conn.execute("DELETE FROM market_snapshots")
        conn.commit()
    logger.info("âœ… å·²æ¸…ç©ºæ‰€æœ‰èˆŠå¿«ç…§")

if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="çœŸå¯¦æ­·å²æ•¸æ“šç²å–å·¥å…·")
    parser.add_argument("--hours", type=int, default=16, help="ç²å–æœ€è¿‘ N å°æ™‚æ•¸æ“š (Max ~16h via public API)")
    parser.add_argument("--clear", action="store_true", help="åŸ·è¡Œå‰å…ˆæ¸…ç©ºèˆŠæ•¸æ“š")
    args = parser.parse_args()

    if args.clear:
        clear_snapshots()

    generate_snapshots_from_real_data(hours=args.hours)
