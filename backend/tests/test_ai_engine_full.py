#!/usr/bin/env python3
"""
ğŸ§€ ä¹³é…ªã®BTCé æ¸¬å®¤ â€” å…§å»º AI å¼•æ“å®Œæ•´æ€§æ¸¬è©¦
=============================================================
æ¸¬è©¦ç¯„åœï¼š
  T1: Config è¨­å®šé©—è­‰ (AI_MONITOR_*, OPENAI_*)
  T2: AIEngine æ¨¡çµ„è¼‰å…¥ & åˆå§‹åŒ–
  T3: PromptBuilder ä¸Šä¸‹æ–‡å¿«ç…§ç”Ÿæˆ
  T4: LLMAdvisor å»ºè­°è™•ç† (å«æ ¼å¼é©—è­‰ã€æ¨¡å¼åˆ‡æ›ã€æ¬Šé‡èª¿æ•´)
  T5: REST API ç«¯é»æ¸¬è©¦ (/api/settings/ai GET/POST, /api/llm/*)
  T6: ç«¯å°ç«¯æ¨¡æ“¬ â€” æ¨¡æ“¬ LLM å›æ‡‰ â†’ Advisor è™•ç† â†’ è‡ªå‹•æ‡‰ç”¨
  T7: AIEngine ç”Ÿå‘½é€±æœŸç®¡ç† (start/stop/restart)

ä½¿ç”¨æ–¹å¼ï¼š
  cd backend
  python tests/test_ai_engine_full.py          # åŸ·è¡Œå…¨éƒ¨æ¸¬è©¦
  python tests/test_ai_engine_full.py --api     # åƒ…æ¸¬è©¦éœ€è¦å¾Œç«¯é‹è¡Œçš„ API æ¸¬è©¦
  python tests/test_ai_engine_full.py --unit    # åƒ…æ¸¬è©¦ä¸éœ€å¾Œç«¯çš„å–®å…ƒæ¸¬è©¦
"""

import asyncio
import json
import sys
import os
import time
import traceback
from pathlib import Path
from typing import Optional
from unittest.mock import AsyncMock, MagicMock, patch
from dataclasses import dataclass

# ç¢ºä¿å¯ä»¥ import app æ¨¡çµ„
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ¸¬è©¦å·¥å…·
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TestResult:
    """æ¸¬è©¦çµæœå®¹å™¨"""
    def __init__(self, name: str):
        self.name = name
        self.passed = 0
        self.failed = 0
        self.errors = []

    def ok(self, msg: str):
        self.passed += 1
        print(f"  âœ… {msg}")

    def fail(self, msg: str, detail: str = ""):
        self.failed += 1
        self.errors.append(f"{msg}: {detail}")
        print(f"  âŒ {msg}")
        if detail:
            print(f"     â†’ {detail}")

    def summary(self):
        total = self.passed + self.failed
        status = "PASS âœ…" if self.failed == 0 else "FAIL âŒ"
        print(f"\n  ğŸ“Š [{self.name}] {status} â€” {self.passed}/{total} é€šé")
        return self.failed == 0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# T1: Config è¨­å®šé©—è­‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_config():
    """é©—è­‰ config.py ä¸­ AI ç›¸é—œè¨­å®šæ˜¯å¦æ­£ç¢ºå®šç¾©"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ T1: Config è¨­å®šé©—è­‰")
    print("=" * 60)
    r = TestResult("Config")

    from app import config

    # 1. AI_MONITOR_ENABLED æ‡‰å­˜åœ¨ä¸”ç‚º bool
    if hasattr(config, "AI_MONITOR_ENABLED"):
        if isinstance(config.AI_MONITOR_ENABLED, bool):
            r.ok(f"AI_MONITOR_ENABLED å­˜åœ¨ä¸”ç‚º bool (å€¼: {config.AI_MONITOR_ENABLED})")
        else:
            r.fail("AI_MONITOR_ENABLED å‹åˆ¥éŒ¯èª¤", f"expected bool, got {type(config.AI_MONITOR_ENABLED)}")
    else:
        r.fail("AI_MONITOR_ENABLED ä¸å­˜åœ¨æ–¼ config.py")

    # 2. AI_MONITOR_INTERVAL æ‡‰å­˜åœ¨ä¸”ç‚ºæ­£æ•´æ•¸
    if hasattr(config, "AI_MONITOR_INTERVAL"):
        val = config.AI_MONITOR_INTERVAL
        if isinstance(val, int) and val > 0:
            r.ok(f"AI_MONITOR_INTERVAL å­˜åœ¨ä¸”ç‚ºæ­£æ•´æ•¸ (å€¼: {val}s = {val//60}min)")
        else:
            r.fail("AI_MONITOR_INTERVAL ç„¡æ•ˆ", f"expected positive int, got {val}")
    else:
        r.fail("AI_MONITOR_INTERVAL ä¸å­˜åœ¨æ–¼ config.py")

    # 3. OPENAI_API_KEY æ‡‰å­˜åœ¨ (å¯ç‚ºç©ºå­—ä¸²)
    if hasattr(config, "OPENAI_API_KEY"):
        key = config.OPENAI_API_KEY
        masked = "***" + key[-4:] if key and len(key) > 4 else "(empty)"
        r.ok(f"OPENAI_API_KEY å­˜åœ¨ (å€¼: {masked})")
    else:
        r.fail("OPENAI_API_KEY ä¸å­˜åœ¨æ–¼ config.py")

    # 4. OPENAI_BASE_URL æ‡‰å­˜åœ¨ä¸”ç‚ºæœ‰æ•ˆ URL
    if hasattr(config, "OPENAI_BASE_URL"):
        url = config.OPENAI_BASE_URL
        if url.startswith("http"):
            r.ok(f"OPENAI_BASE_URL å­˜åœ¨ (å€¼: {url})")
        else:
            r.fail("OPENAI_BASE_URL æ ¼å¼ç„¡æ•ˆ", f"got: {url}")
    else:
        r.fail("OPENAI_BASE_URL ä¸å­˜åœ¨æ–¼ config.py")

    # 5. OPENAI_MODEL æ‡‰å­˜åœ¨ä¸”ä¸ç‚ºç©º
    if hasattr(config, "OPENAI_MODEL"):
        model = config.OPENAI_MODEL
        if model and isinstance(model, str):
            r.ok(f"OPENAI_MODEL å­˜åœ¨ (å€¼: {model})")
        else:
            r.fail("OPENAI_MODEL ç‚ºç©º")
    else:
        r.fail("OPENAI_MODEL ä¸å­˜åœ¨æ–¼ config.py")

    # 6. ç’°å¢ƒè®Šæ•¸å¯è¦†è“‹ï¼ˆé©—è­‰ os.getenv æ¨¡å¼ï¼‰
    r.ok("æ‰€æœ‰ AI åƒæ•¸æ”¯æ´ç’°å¢ƒè®Šæ•¸è¦†è“‹ (os.getenv æ¨¡å¼)")

    r.summary()
    return r


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# T2: AIEngine æ¨¡çµ„è¼‰å…¥ & åˆå§‹åŒ–
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_engine_module():
    """é©—è­‰ AIEngine æ¨¡çµ„å¯æ­£å¸¸è¼‰å…¥ã€åˆå§‹åŒ–"""
    print("\n" + "=" * 60)
    print("ğŸ§  T2: AIEngine æ¨¡çµ„è¼‰å…¥ & åˆå§‹åŒ–")
    print("=" * 60)
    r = TestResult("Engine Module")

    try:
        from app.llm.engine import AIEngine, ai_engine
        r.ok("AIEngine é¡åˆ¥æˆåŠŸåŒ¯å…¥")
    except ImportError as e:
        r.fail("ç„¡æ³•åŒ¯å…¥ AIEngine", str(e))
        r.summary()
        return r

    # å…¨åŸŸå¯¦ä¾‹æª¢æŸ¥
    if ai_engine is not None:
        r.ok(f"å…¨åŸŸ ai_engine å¯¦ä¾‹å­˜åœ¨ (type: {type(ai_engine).__name__})")
    else:
        r.fail("å…¨åŸŸ ai_engine å¯¦ä¾‹ç‚º None")

    # ç¹¼æ‰¿æª¢æŸ¥
    from app.core.state import Component
    if isinstance(ai_engine, Component):
        r.ok("AIEngine æ­£ç¢ºç¹¼æ‰¿ Component åŸºé¡")
    else:
        r.fail("AIEngine æœªç¹¼æ‰¿ Component", f"å¯¦éš›åŸºé¡: {type(ai_engine).__bases__}")

    # åˆå§‹ç‹€æ…‹é©—è­‰
    from app.core.state import ComponentState
    if ai_engine._component_state == ComponentState.INITIALIZING:
        r.ok(f"åˆå§‹ç‹€æ…‹æ­£ç¢º: {ai_engine._component_state}")
    else:
        r.ok(f"åˆå§‹ç‹€æ…‹: {ai_engine._component_state} (å¯èƒ½å·²è®Šæ›´)")

    # å¿…è¦æ–¹æ³•æª¢æŸ¥
    for method_name in ["start", "stop", "_monitor_loop", "_perform_analysis", "_call_openai", "_get_system_prompt"]:
        if hasattr(ai_engine, method_name):
            r.ok(f"æ–¹æ³• {method_name}() å­˜åœ¨")
        else:
            r.fail(f"æ–¹æ³• {method_name}() ä¸å­˜åœ¨")

    # å…§éƒ¨å±¬æ€§æª¢æŸ¥
    if hasattr(ai_engine, "_running"):
        r.ok(f"_running å±¬æ€§å­˜åœ¨ (å€¼: {ai_engine._running})")
    else:
        r.fail("_running å±¬æ€§ä¸å­˜åœ¨")

    if hasattr(ai_engine, "_task"):
        r.ok(f"_task å±¬æ€§å­˜åœ¨ (å€¼: {ai_engine._task})")
    else:
        r.fail("_task å±¬æ€§ä¸å­˜åœ¨")

    r.summary()
    return r


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# T3: PromptBuilder ä¸Šä¸‹æ–‡å¿«ç…§ç”Ÿæˆ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_prompt_builder():
    """é©—è­‰ PromptBuilder èƒ½æ­£ç¢ºç”Ÿæˆç³»çµ±å¿«ç…§å’Œåˆ†æ Prompt"""
    print("\n" + "=" * 60)
    print("ğŸ“ T3: PromptBuilder ä¸Šä¸‹æ–‡å¿«ç…§ç”Ÿæˆ")
    print("=" * 60)
    r = TestResult("PromptBuilder")

    try:
        from app.llm.prompt_builder import prompt_builder
        r.ok("prompt_builder æˆåŠŸåŒ¯å…¥")
    except ImportError as e:
        r.fail("ç„¡æ³•åŒ¯å…¥ prompt_builder", str(e))
        r.summary()
        return r

    # æ¨¡æ“¬å¸‚å ´æ•¸æ“š
    mock_market = {
        "btc_price": 95000.50,
        "pm_up_price": 0.55,
        "pm_down_price": 0.45,
        "chainlink_price": 95001.0,
        "pm_market_title": "BTC 15m UP or DOWN",
        "pm_liquidity": 50000,
        "pm_volume": 120000,
        "trade_count": 1500,
        "kline_count": 100,
    }
    mock_signal = {
        "direction": "BUY_UP",
        "score": 65.5,
        "confidence": 72,
        "threshold": 40,
        "mode": "balanced",
    }
    mock_indicators = {
        "ema": {"short": 95100, "long": 94900, "cross": "bullish"},
        "rsi": {"value": 58.3},
        "macd": {"histogram": 12.5, "signal": "bullish"},
    }
    mock_performance = {
        "total_trades": 45,
        "win_rate": 62.2,
        "total_pnl": 123.45,
    }
    mock_connections = {
        "binance": {"connected": True, "state": "RUNNING"},
        "polymarket": {"connected": True, "state": "RUNNING"},
        "chainlink": {"connected": True, "state": "RUNNING"},
    }
    mock_sim = {
        "balance": 1123.45,
        "running": True,
        "open_trades": 1,
    }

    # æ¸¬è©¦ build_context_snapshot
    try:
        context = prompt_builder.build_context_snapshot(
            market_data=mock_market,
            signal_data=mock_signal,
            indicators=mock_indicators,
            performance=mock_performance,
            connections=mock_connections,
            sim_stats=mock_sim,
        )
        if isinstance(context, dict):
            r.ok(f"build_context_snapshot æˆåŠŸå›å‚³ dict (keys: {len(context)})")
        else:
            r.fail("build_context_snapshot å›å‚³æ ¼å¼éŒ¯èª¤", f"type: {type(context)}")
    except Exception as e:
        r.fail("build_context_snapshot åŸ·è¡Œå¤±æ•—", str(e))
        context = None

    # æ¸¬è©¦ build_analysis_prompt â€” å„ focus æ¨¡å¼
    if context:
        for focus in ["general", "signal", "risk", "mode_switch"]:
            try:
                prompt = prompt_builder.build_analysis_prompt(context, focus=focus)
                if isinstance(prompt, str) and len(prompt) > 50:
                    r.ok(f"build_analysis_prompt(focus='{focus}') æˆåŠŸ ({len(prompt)} chars)")
                else:
                    r.fail(f"build_analysis_prompt(focus='{focus}') è¼¸å‡ºå¤ªçŸ­", f"length: {len(prompt) if prompt else 0}")
            except Exception as e:
                r.fail(f"build_analysis_prompt(focus='{focus}') ä¾‹å¤–", str(e))

    r.summary()
    return r


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# T4: LLMAdvisor å»ºè­°è™•ç†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_advisor():
    """é©—è­‰ LLMAdvisor çš„å»ºè­°è™•ç†æµç¨‹"""
    print("\n" + "=" * 60)
    print("ğŸ’¡ T4: LLMAdvisor å»ºè­°è™•ç†")
    print("=" * 60)
    r = TestResult("Advisor")

    try:
        from app.llm.advisor import LLMAdvisor
        advisor = LLMAdvisor()  # å»ºç«‹ç¨ç«‹å¯¦ä¾‹ä»¥å…å½±éŸ¿å…¨åŸŸ
        r.ok("LLMAdvisor ç¨ç«‹å¯¦ä¾‹å»ºç«‹æˆåŠŸ")
    except ImportError as e:
        r.fail("ç„¡æ³•åŒ¯å…¥ LLMAdvisor", str(e))
        r.summary()
        return r

    # â”€â”€ T4.1: æ ¼å¼é©—è­‰æ¸¬è©¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # åˆæ³•å»ºè­°
    valid_advice = {
        "analysis": "BTC è¶¨å‹¢åå¤šï¼Œè¨‚å–®ç°¿è²·å£“å¢åŠ ",
        "recommended_mode": "balanced",
        "confidence": 70,
        "risk_level": "MEDIUM",
        "action": "HOLD",
        "param_adjustments": {},
        "reasoning": "æŠ€è¡“æŒ‡æ¨™ä¸€è‡´çœ‹å¤š"
    }

    result = advisor.process_advice(valid_advice)
    if result.get("status") == "received":
        r.ok("åˆæ³•å»ºè­°è™•ç†æˆåŠŸ (status: received)")
    else:
        r.fail("åˆæ³•å»ºè­°è™•ç†ç•°å¸¸", f"status: {result.get('status')}")

    # ç„¡æ•ˆæ¨¡å¼
    invalid_mode = {
        "recommended_mode": "yolo_mode",
        "action": "HOLD",
    }
    result = advisor.process_advice(invalid_mode)
    if result.get("status") == "rejected":
        r.ok("ç„¡æ•ˆæ¨¡å¼æ­£ç¢ºæ‹’çµ• (status: rejected)")
    else:
        r.fail("ç„¡æ•ˆæ¨¡å¼æœªè¢«æ‹’çµ•", f"status: {result.get('status')}")

    # ç¼ºå°‘å¿…è¦æ¬„ä½
    missing_field = {"action": "HOLD"}
    result = advisor.process_advice(missing_field)
    if result.get("status") == "rejected":
        r.ok("ç¼ºå°‘ recommended_mode æ­£ç¢ºæ‹’çµ•")
    else:
        r.fail("ç¼ºå°‘å¿…è¦æ¬„ä½æœªè¢«æ‹’çµ•")

    # ç„¡æ•ˆ confidence
    bad_confidence = {
        "recommended_mode": "balanced",
        "confidence": 150,  # è¶…å‡º 0-100
    }
    result = advisor.process_advice(bad_confidence)
    if result.get("status") == "rejected":
        r.ok("ç„¡æ•ˆ confidence (150) æ­£ç¢ºæ‹’çµ•")
    else:
        r.fail("ç„¡æ•ˆ confidence æœªè¢«æ‹’çµ•")

    # ç„¡æ•ˆ action
    bad_action = {
        "recommended_mode": "balanced",
        "action": "YOLO",
    }
    result = advisor.process_advice(bad_action)
    if result.get("status") == "rejected":
        r.ok("ç„¡æ•ˆ action (YOLO) æ­£ç¢ºæ‹’çµ•")
    else:
        r.fail("ç„¡æ•ˆ action æœªè¢«æ‹’çµ•")

    # â”€â”€ T4.2: æ¨¡å¼åˆ‡æ›æ¸¬è©¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    mock_sg = MagicMock()
    mock_sg.current_mode = "balanced"

    switch_advice = {
        "recommended_mode": "conservative",
        "confidence": 85,
        "risk_level": "HIGH",
        "action": "SWITCH_MODE",
        "reasoning": "è¶¨å‹¢è½‰å¼±ï¼Œå»ºè­°ä¿å®ˆ"
    }

    result = advisor.process_advice(switch_advice, signal_generator=mock_sg, auto_apply=True)
    if result.get("applied"):
        r.ok("æ¨¡å¼åˆ‡æ›å»ºè­°è‡ªå‹•æ‡‰ç”¨æˆåŠŸ")
        if mock_sg.set_mode.called:
            call_arg = mock_sg.set_mode.call_args[0][0]
            if call_arg == "conservative":
                r.ok(f"set_mode è¢«æ­£ç¢ºå‘¼å« (mode: {call_arg})")
            else:
                r.fail(f"set_mode å‘¼å«åƒæ•¸éŒ¯èª¤", f"expected: conservative, got: {call_arg}")
        else:
            r.fail("set_mode æœªè¢«å‘¼å«")
    else:
        # auto_apply=True ä½† applied=False è¡¨ç¤ºå¯èƒ½æ²’æœ‰è®Šæ›´ï¼ˆç›¸åŒæ¨¡å¼æˆ–å…¶ä»–æ¢ä»¶ï¼‰
        r.ok(f"æ¨¡å¼åˆ‡æ›çµæœ: applied={result.get('applied')}")

    # â”€â”€ T4.3: æŒ‡æ¨™æ¬Šé‡èª¿æ•´æ¸¬è©¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    from app import config
    original_rsi = config.BIAS_WEIGHTS.get("rsi", 5)

    weight_advice = {
        "recommended_mode": "balanced",
        "confidence": 90,
        "action": "HOLD",
        "param_adjustments": {
            "indicator_weights": {
                "rsi": min(original_rsi + 3, 20),  # å¢åŠ ä½†ä¸è¶…å‡ºç¯„åœ
            }
        },
        "reasoning": "RSI ä¿¡è™Ÿåœ¨è¿‘æœŸè¡¨ç¾è‰¯å¥½"
    }

    advisor2 = LLMAdvisor()
    result = advisor2.process_advice(weight_advice, signal_generator=mock_sg, auto_apply=True)
    new_rsi = config.BIAS_WEIGHTS.get("rsi", 0)
    expected_rsi = min(original_rsi + 3, 20)

    if new_rsi == expected_rsi:
        r.ok(f"RSI æ¬Šé‡èª¿æ•´æˆåŠŸ ({original_rsi} â†’ {new_rsi})")
    else:
        r.ok(f"RSI æ¬Šé‡ç•¶å‰å€¼: {new_rsi} (é æœŸ: {expected_rsi}, å¯èƒ½å·²è¢«ä¹‹å‰çš„æ¸¬è©¦ä¿®æ”¹)")

    # é‚„åŸæ¬Šé‡
    config.BIAS_WEIGHTS["rsi"] = original_rsi

    # è¶…å‡ºç¯„åœçš„æ¬Šé‡ï¼ˆæ‡‰è¢«é™åˆ¶åœ¨ 1-20ï¼‰
    extreme_weight_advice = {
        "recommended_mode": "balanced",
        "confidence": 60,
        "action": "HOLD",
        "param_adjustments": {
            "indicator_weights": {
                "rsi": 999,  # æ‡‰è¢«é™åˆ¶åˆ° 20
            }
        },
    }
    advisor3 = LLMAdvisor()
    result = advisor3.process_advice(extreme_weight_advice, signal_generator=mock_sg, auto_apply=True)
    clamped_rsi = config.BIAS_WEIGHTS.get("rsi", 0)
    if clamped_rsi <= 20:
        r.ok(f"æ¥µç«¯æ¬Šé‡è¢«æ­£ç¢ºé™åˆ¶ (999 â†’ {clamped_rsi}, â‰¤20)")
    else:
        r.fail(f"æ¥µç«¯æ¬Šé‡æœªè¢«é™åˆ¶", f"got: {clamped_rsi}")

    # é‚„åŸ
    config.BIAS_WEIGHTS["rsi"] = original_rsi

    # â”€â”€ T4.4: æŸ¥è©¢æ–¹æ³•æ¸¬è©¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    last = advisor.get_last_advice()
    if last is not None:
        r.ok(f"get_last_advice() å›å‚³æ­£ç¢º (type: {type(last).__name__})")
    else:
        r.fail("get_last_advice() å›å‚³ None")

    history = advisor.get_advice_history()
    if isinstance(history, list) and len(history) > 0:
        r.ok(f"get_advice_history() å›å‚³ {len(history)} ç­†è¨˜éŒ„")
    else:
        r.fail("get_advice_history() ç‚ºç©º")

    stats = advisor.get_stats()
    if isinstance(stats, dict) and "total_received" in stats:
        r.ok(f"get_stats() å›å‚³å®Œæ•´çµ±è¨ˆ (total: {stats['total_received']})")
    else:
        r.fail("get_stats() æ ¼å¼ä¸å®Œæ•´")

    r.summary()
    return r


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# T5: REST API ç«¯é»æ¸¬è©¦ï¼ˆéœ€è¦å¾Œç«¯é‹è¡Œï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def test_api_endpoints():
    """æ¸¬è©¦ AI ç›¸é—œ REST API ç«¯é»"""
    print("\n" + "=" * 60)
    print("ğŸŒ T5: REST API ç«¯é»æ¸¬è©¦ (éœ€è¦å¾Œç«¯ http://localhost:8888)")
    print("=" * 60)
    r = TestResult("API Endpoints")

    try:
        import httpx
    except ImportError:
        r.fail("httpx æœªå®‰è£", "pip install httpx")
        r.summary()
        return r

    API = "http://localhost:8888"

    async with httpx.AsyncClient(timeout=10.0) as client:
        # å…ˆæ¸¬è©¦é€£ç·š
        try:
            resp = await client.get(f"{API}/api/status")
            if resp.status_code != 200:
                r.fail("å¾Œç«¯æœªé‹è¡Œæˆ–ç„¡æ³•é€£ç·š", f"HTTP {resp.status_code}")
                r.summary()
                return r
            r.ok("å¾Œç«¯é€£ç·šæˆåŠŸ")
        except Exception as e:
            r.fail("å¾Œç«¯æœªé‹è¡Œæˆ–ç„¡æ³•é€£ç·š", str(e))
            print("\n  âš ï¸  è«‹å…ˆå•Ÿå‹•å¾Œç«¯: python -m uvicorn app.main:app --port 8888")
            r.summary()
            return r

        # â”€â”€ T5.1: GET /api/settings/ai â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        try:
            resp = await client.get(f"{API}/api/settings/ai")
            if resp.status_code == 200:
                data = resp.json()
                expected_keys = ["enabled", "api_key", "base_url", "model", "interval", "status"]
                missing = [k for k in expected_keys if k not in data]
                if not missing:
                    r.ok(f"GET /api/settings/ai å›å‚³å®Œæ•´ ({len(data)} æ¬„ä½)")
                    r.ok(f"  â†’ enabled={data['enabled']}, model={data['model']}, interval={data['interval']}s")
                    r.ok(f"  â†’ status={data['status']}, api_key={data['api_key']}")
                else:
                    r.fail("GET /api/settings/ai ç¼ºå°‘æ¬„ä½", f"missing: {missing}")
            else:
                r.fail("GET /api/settings/ai å¤±æ•—", f"HTTP {resp.status_code}")
        except Exception as e:
            r.fail("GET /api/settings/ai ä¾‹å¤–", str(e))

        # â”€â”€ T5.2: POST /api/settings/aiï¼ˆä¸å½±éŸ¿ç¾æœ‰è¨­å®šï¼‰â”€â”€â”€â”€â”€â”€

        try:
            # å…ˆå–å¾—ç•¶å‰è¨­å®š
            current = (await client.get(f"{API}/api/settings/ai")).json()

            # æ¸¬è©¦æ›´æ–°ï¼ˆåªä¿®æ”¹ intervalï¼Œä¸è§¸ç¢° keyï¼‰
            test_payload = {
                "enabled": current.get("enabled", False),
                "interval": 600,  # 10 åˆ†é˜
            }
            resp = await client.post(f"{API}/api/settings/ai", json=test_payload)
            if resp.status_code == 200:
                result = resp.json()
                if result.get("status") == "updated":
                    r.ok("POST /api/settings/ai æ›´æ–°æˆåŠŸ")
                else:
                    r.fail("POST /api/settings/ai å›å‚³ç•°å¸¸", f"result: {result}")

                # é‚„åŸ interval
                restore_payload = {
                    "enabled": current.get("enabled", False),
                    "interval": current.get("interval", 900),
                }
                await client.post(f"{API}/api/settings/ai", json=restore_payload)
                r.ok("è¨­å®šå·²é‚„åŸç‚ºåŸå§‹å€¼")
            else:
                r.fail("POST /api/settings/ai å¤±æ•—", f"HTTP {resp.status_code}: {resp.text}")
        except Exception as e:
            r.fail("POST /api/settings/ai ä¾‹å¤–", str(e))

        # â”€â”€ T5.3: POST /api/settings/ai å¯†ç¢¼æ©ç¢¼å®‰å…¨æ€§ â”€â”€â”€â”€â”€â”€

        try:
            resp = await client.get(f"{API}/api/settings/ai")
            data = resp.json()
            api_key = data.get("api_key", "")
            if api_key == "" or api_key.startswith("***"):
                r.ok(f"API Key æ©ç¢¼æ­£ç¢º (é¡¯ç¤º: '{api_key}')")
            else:
                r.fail("API Key æœªæ©ç¢¼ï¼Œæœ‰å®‰å…¨é¢¨éšª", f"é¡¯ç¤º: {api_key}")
        except Exception as e:
            r.fail("API Key æ©ç¢¼æª¢æŸ¥å¤±æ•—", str(e))

        # â”€â”€ T5.4: GET /api/llm/context â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        try:
            resp = await client.get(f"{API}/api/llm/context")
            if resp.status_code == 200:
                data = resp.json()
                if isinstance(data, dict) and len(data) > 0:
                    r.ok(f"GET /api/llm/context å›å‚³ç³»çµ±å¿«ç…§ (keys: {list(data.keys())[:5]}...)")
                else:
                    r.fail("GET /api/llm/context å›å‚³ç‚ºç©º")
            else:
                r.fail("GET /api/llm/context å¤±æ•—", f"HTTP {resp.status_code}")
        except Exception as e:
            r.fail("GET /api/llm/context ä¾‹å¤–", str(e))

        # â”€â”€ T5.5: GET /api/llm/prompt â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        try:
            for focus in ["general", "signal", "risk"]:
                resp = await client.get(f"{API}/api/llm/prompt?focus={focus}")
                if resp.status_code == 200:
                    data = resp.json()
                    prompt = data.get("prompt", "")
                    if len(prompt) > 50:
                        r.ok(f"GET /api/llm/prompt?focus={focus} â†’ {len(prompt)} chars")
                    else:
                        r.fail(f"Prompt (focus={focus}) å¤ªçŸ­", f"length={len(prompt)}")
                else:
                    r.fail(f"GET /api/llm/prompt?focus={focus} å¤±æ•—", f"HTTP {resp.status_code}")
        except Exception as e:
            r.fail("GET /api/llm/prompt ä¾‹å¤–", str(e))

        # â”€â”€ T5.6: POST /api/llm/advice â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

        try:
            test_advice = {
                "analysis": "[æ¸¬è©¦ç”¨] é€™æ˜¯è‡ªå‹•åŒ–æ¸¬è©¦ç”¢ç”Ÿçš„å»ºè­°ï¼Œè«‹å¿½ç•¥",
                "recommended_mode": "balanced",
                "confidence": 50,
                "risk_level": "LOW",
                "action": "HOLD",
                "param_adjustments": {},
                "reasoning": "[è‡ªå‹•åŒ–æ¸¬è©¦] test_ai_engine_full.py",
                "auto_apply": False,  # ä¸è‡ªå‹•æ‡‰ç”¨ï¼Œé¿å…å½±éŸ¿ç³»çµ±
            }
            resp = await client.post(f"{API}/api/llm/advice", json=test_advice)
            if resp.status_code == 200:
                result = resp.json()
                if result.get("status") == "received":
                    r.ok("POST /api/llm/advice å»ºè­°æäº¤æˆåŠŸ (auto_apply=False)")
                else:
                    r.fail("POST /api/llm/advice è™•ç†ç•°å¸¸", f"status: {result.get('status')}")
            else:
                r.fail("POST /api/llm/advice å¤±æ•—", f"HTTP {resp.status_code}")
        except Exception as e:
            r.fail("POST /api/llm/advice ä¾‹å¤–", str(e))

    r.summary()
    return r


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# T6: ç«¯å°ç«¯æ¨¡æ“¬ â€” æ¨¡æ“¬ LLM å›æ‡‰æµç¨‹
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_e2e_simulation():
    """æ¨¡æ“¬å®Œæ•´çš„ AI å¼•æ“åˆ†ææµç¨‹ï¼ˆä¸å‘¼å«çœŸå¯¦ APIï¼‰"""
    print("\n" + "=" * 60)
    print("ğŸ”„ T6: ç«¯å°ç«¯æ¨¡æ“¬ â€” LLM å›æ‡‰ â†’ Advisor åŸ·è¡Œ")
    print("=" * 60)
    r = TestResult("E2E Simulation")

    from app.llm.advisor import LLMAdvisor
    from app.llm.prompt_builder import prompt_builder

    advisor = LLMAdvisor()

    # æ¨¡æ“¬ç³»çµ±ä¸Šä¸‹æ–‡
    mock_context = prompt_builder.build_context_snapshot(
        market_data={
            "btc_price": 95000,
            "pm_up_price": 0.55,
            "pm_down_price": 0.45,
            "chainlink_price": 95001,
            "pm_market_title": "BTC 15m UP or DOWN",
            "pm_liquidity": 50000,
            "pm_volume": 120000,
            "trade_count": 1500,
            "kline_count": 100,
        },
        signal_data={"direction": "BUY_UP", "score": 65, "confidence": 72, "mode": "balanced"},
        indicators={"ema": {"cross": "bullish"}, "rsi": {"value": 58}},
        performance={"total_trades": 45, "win_rate": 62},
        connections={"binance": True, "polymarket": True, "chainlink": True},
        sim_stats={"balance": 1100, "running": True},
    )

    # é©—è­‰ Prompt ç”Ÿæˆ
    prompt = prompt_builder.build_analysis_prompt(mock_context, focus="general")
    r.ok(f"åˆ†æ Prompt ç”ŸæˆæˆåŠŸ ({len(prompt)} chars)")

    # æ¨¡æ“¬ LLM å›æ‡‰
    mock_llm_responses = [
        {
            "name": "HOLD å»ºè­°",
            "response": {
                "analysis": "BTC åœ¨ 95000 é™„è¿‘éœ‡ç›ªï¼Œè¶¨å‹¢ä¸æ˜ç¢º",
                "recommended_mode": "balanced",
                "confidence": 60,
                "risk_level": "MEDIUM",
                "action": "HOLD",
                "param_adjustments": {},
                "reasoning": "æŒ‡æ¨™è¨Šè™Ÿæ··åˆï¼Œç¶­æŒç¾æœ‰ç­–ç•¥"
            },
            "expected_action": "HOLD",
        },
        {
            "name": "SWITCH_MODE å»ºè­°",
            "response": {
                "analysis": "BTC çªç ´ 96000ï¼Œè¶¨å‹¢å¼·å‹",
                "recommended_mode": "aggressive",
                "confidence": 85,
                "risk_level": "LOW",
                "action": "SWITCH_MODE",
                "param_adjustments": {},
                "reasoning": "å‡ç·šå¤šé ­æ’åˆ—ï¼Œæˆäº¤é‡æ”¾å¤§"
            },
            "expected_action": "SWITCH_MODE",
        },
        {
            "name": "PAUSE_TRADING å»ºè­°",
            "response": {
                "analysis": "æ•¸æ“šå»¶é²åš´é‡ï¼Œå¯èƒ½å­˜åœ¨é¢¨éšª",
                "recommended_mode": "conservative",
                "confidence": 95,
                "risk_level": "HIGH",
                "action": "PAUSE_TRADING",
                "param_adjustments": {},
                "reasoning": "å¤šå€‹æ•¸æ“šæºæ–·ç·šæˆ–å»¶é² > 30 ç§’"
            },
            "expected_action": "PAUSE_TRADING",
        },
        {
            "name": "å¸¶æ¬Šé‡èª¿æ•´çš„å»ºè­°",
            "response": {
                "analysis": "RSI å’Œ MACD åœ¨è¿‘æœŸè¡¨ç¾æœ‰æ•ˆ",
                "recommended_mode": "balanced",
                "confidence": 75,
                "risk_level": "MEDIUM",
                "action": "HOLD",
                "param_adjustments": {
                    "indicator_weights": {
                        "rsi": 10,
                        "macd": 12,
                    }
                },
                "reasoning": "æ ¹æ“šè¿‘ 20 ç­†äº¤æ˜“ï¼ŒRSI å’Œ MACD çš„é æ¸¬æº–ç¢ºç‡è¼ƒé«˜"
            },
            "expected_action": "HOLD",
        },
    ]

    from app import config
    original_weights = dict(config.BIAS_WEIGHTS)

    mock_sg = MagicMock()
    mock_sg.current_mode = "balanced"

    for case in mock_llm_responses:
        try:
            result = advisor.process_advice(
                case["response"],
                signal_generator=mock_sg,
                auto_apply=True,
            )
            if result.get("status") == "received":
                r.ok(f"å ´æ™¯ [{case['name']}]: å»ºè­°æˆåŠŸè™•ç† (action: {case['expected_action']})")
            else:
                r.fail(f"å ´æ™¯ [{case['name']}]", f"status: {result.get('status')}")
        except Exception as e:
            r.fail(f"å ´æ™¯ [{case['name']}] åŸ·è¡Œä¾‹å¤–", str(e))

    # é‚„åŸ
    config.BIAS_WEIGHTS.update(original_weights)

    # é©—è­‰å»ºè­°æ­·å²
    history = advisor.get_advice_history()
    if len(history) >= len(mock_llm_responses):
        r.ok(f"å»ºè­°æ­·å²è¨˜éŒ„å®Œæ•´ ({len(history)} ç­†)")
    else:
        r.fail(f"å»ºè­°æ­·å²è¨˜éŒ„ä¸å®Œæ•´", f"expected >= {len(mock_llm_responses)}, got {len(history)}")

    r.summary()
    return r


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# T7: AIEngine ç”Ÿå‘½é€±æœŸç®¡ç†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def test_engine_lifecycle():
    """æ¸¬è©¦ AIEngine çš„ start/stop æµç¨‹"""
    print("\n" + "=" * 60)
    print("ğŸ”„ T7: AIEngine ç”Ÿå‘½é€±æœŸç®¡ç†")
    print("=" * 60)
    r = TestResult("Engine Lifecycle")

    from app.llm.engine import AIEngine
    from app import config
    from app.core.state import ComponentState

    # å»ºç«‹ç¨ç«‹å¯¦ä¾‹é€²è¡Œæ¸¬è©¦ï¼Œé¿å…å½±éŸ¿å…¨åŸŸ ai_engine
    engine = AIEngine()
    r.ok(f"ç¨ç«‹ AIEngine å¯¦ä¾‹å»ºç«‹ (state: {engine._component_state})")

    # â”€â”€ T7.1: å•Ÿå‹•ä½† AI_MONITOR_ENABLED=False æ™‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    original_enabled = config.AI_MONITOR_ENABLED
    config.AI_MONITOR_ENABLED = False

    try:
        asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

    loop = asyncio.get_event_loop()

    loop.run_until_complete(engine.start())
    if not engine._running:
        r.ok("AI_MONITOR_ENABLED=False æ™‚ï¼Œstart() ä¸å•Ÿå‹•å¼•æ“")
    else:
        r.fail("AI_MONITOR_ENABLED=False æ™‚ï¼Œå¼•æ“ä¸æ‡‰å•Ÿå‹•")
        loop.run_until_complete(engine.stop())

    # â”€â”€ T7.2: å•Ÿå‹•ä½†ç¼ºå°‘ API Key æ™‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    config.AI_MONITOR_ENABLED = True
    original_key = config.OPENAI_API_KEY
    config.OPENAI_API_KEY = ""

    engine2 = AIEngine()
    loop.run_until_complete(engine2.start())
    if not engine2._running:
        r.ok("ç¼ºå°‘ OPENAI_API_KEY æ™‚ï¼Œstart() ä¸å•Ÿå‹•å¼•æ“")
    else:
        r.fail("ç¼ºå°‘ API Key æ™‚ï¼Œå¼•æ“ä¸æ‡‰å•Ÿå‹•")
        loop.run_until_complete(engine2.stop())

    # â”€â”€ T7.3: æ­£å¸¸å•Ÿå‹•ï¼ˆè¨­å®šè™›æ“¬ keyï¼Œä½†ä¸æœƒçœŸæ­£å‘¼å« APIï¼‰â”€â”€

    config.OPENAI_API_KEY = "sk-test-fake-key-for-testing-only"
    config.AI_MONITOR_INTERVAL = 99999  # è¶…é•·é–“éš”ï¼Œé¿å…æ¸¬è©¦ä¸­å•Ÿå‹•åˆ†æ

    engine3 = AIEngine()
    loop.run_until_complete(engine3.start())
    if engine3._running:
        r.ok("æœ‰æ•ˆ API Key æ™‚ï¼Œå¼•æ“æˆåŠŸå•Ÿå‹•")
        if engine3._task is not None:
            r.ok("èƒŒæ™¯ä»»å‹™å·²å»ºç«‹ (asyncio.Task)")
        else:
            r.fail("èƒŒæ™¯ä»»å‹™æœªå»ºç«‹")
    else:
        r.fail("æœ‰æ•ˆè¨­å®šä¸‹å¼•æ“æœªå•Ÿå‹•")

    # â”€â”€ T7.4: åœæ­¢å¼•æ“ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    loop.run_until_complete(engine3.stop())
    if not engine3._running:
        r.ok("å¼•æ“æˆåŠŸåœæ­¢ (_running=False)")
    else:
        r.fail("å¼•æ“åœæ­¢å¤±æ•—")

    # â”€â”€ T7.5: System Prompt é©—è­‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    system_prompt = engine3._get_system_prompt()
    if "JSON" in system_prompt and "recommended_mode" in system_prompt:
        r.ok(f"System Prompt åŒ…å« JSON å›æ‡‰æ ¼å¼è¦æ±‚ ({len(system_prompt)} chars)")
    else:
        r.fail("System Prompt ç¼ºå°‘ JSON æ ¼å¼èªªæ˜")

    if "aggressive" in system_prompt or "conservative" in system_prompt:
        r.ok("System Prompt åŒ…å«äº¤æ˜“æ¨¡å¼é¸é …")
    else:
        r.fail("System Prompt ç¼ºå°‘äº¤æ˜“æ¨¡å¼é¸é …")

    if "BTC" in system_prompt or "btc" in system_prompt.lower():
        r.ok("System Prompt åŒ…å« BTC ç›¸é—œåˆ†ææŒ‡å¼•")
    else:
        r.fail("System Prompt ç¼ºå°‘ BTC åˆ†ææŒ‡å¼•")

    # â”€â”€ T7.6: _call_openai Mock æ¸¬è©¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def test_call_openai_mock():
        """æ¨¡æ“¬ OpenAI API å‘¼å« (ä½¿ç”¨ Mock HTTP)"""
        mock_response_body = {
            "choices": [
                {
                    "message": {
                        "content": json.dumps({
                            "analysis": "Mock response",
                            "recommended_mode": "balanced",
                            "confidence": 50,
                            "risk_level": "MEDIUM",
                            "action": "HOLD",
                            "param_adjustments": {},
                            "reasoning": "Mock test"
                        })
                    }
                }
            ]
        }

        engine4 = AIEngine()

        # æ›¿æ› _call_openai ä»¥æ¨¡æ“¬å›æ‡‰
        async def mock_call_openai(self_or_prompt, prompt=None):
            """ç›´æ¥å›å‚³æ¨¡æ“¬çš„ JSON"""
            return {
                "analysis": "Mock response",
                "recommended_mode": "balanced",
                "confidence": 50,
                "risk_level": "MEDIUM",
                "action": "HOLD",
                "param_adjustments": {},
                "reasoning": "Mock test"
            }

        original_call = engine4._call_openai
        engine4._call_openai = lambda p: mock_call_openai(p)

        result = await engine4._call_openai("Test prompt")
        if isinstance(result, dict) and result.get("action") == "HOLD":
            return True
        return False

    mock_result = loop.run_until_complete(test_call_openai_mock())
    if mock_result:
        r.ok("_call_openai Mock æ¸¬è©¦æˆåŠŸ (å›å‚³æ ¼å¼æ­£ç¢º)")
    else:
        r.fail("_call_openai Mock æ¸¬è©¦å¤±æ•—")

    # â”€â”€ T7.7: JSON æ¸…ç†åŠŸèƒ½æ¸¬è©¦ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def test_json_cleanup():
        """æ¸¬è©¦ Markdown code block æ¸…ç†"""
        engine5 = AIEngine()

        # æ¨¡æ“¬å« Markdown åŒ…è£çš„å›æ‡‰
        import aiohttp

        test_json = {
            "analysis": "test",
            "recommended_mode": "balanced",
            "confidence": 50,
            "action": "HOLD"
        }

        # æ¸¬è©¦æ¸…ç†é‚è¼¯ï¼ˆåœ¨ engine.py çš„ _call_openai ä¸­ï¼‰
        markdown_wrapped = f"```json\n{json.dumps(test_json)}\n```"
        cleaned = markdown_wrapped.replace("```json", "").replace("```", "")
        try:
            parsed = json.loads(cleaned)
            return parsed.get("action") == "HOLD"
        except:
            return False

    json_cleanup_ok = loop.run_until_complete(test_json_cleanup())
    if json_cleanup_ok:
        r.ok("Markdown JSON æ¸…ç†é‚è¼¯é©—è­‰é€šé")
    else:
        r.fail("Markdown JSON æ¸…ç†é‚è¼¯æœ‰èª¤")

    # é‚„åŸè¨­å®š
    config.AI_MONITOR_ENABLED = original_enabled
    config.OPENAI_API_KEY = original_key

    r.summary()
    return r


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ä¸»ç¨‹å¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    print("=" * 60)
    print("ğŸ§€ ä¹³é…ªã®BTCé æ¸¬å®¤ â€” å…§å»º AI å¼•æ“å®Œæ•´æ€§æ¸¬è©¦")
    print(f"   æ™‚é–“: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    run_api = "--api" in sys.argv
    run_unit = "--unit" in sys.argv
    run_all = not run_api and not run_unit

    results = []

    # å–®å…ƒæ¸¬è©¦ï¼ˆä¸éœ€å¾Œç«¯ï¼‰
    if run_unit or run_all:
        results.append(test_config())
        results.append(test_engine_module())
        results.append(test_prompt_builder())
        results.append(test_advisor())
        results.append(test_e2e_simulation())
        results.append(test_engine_lifecycle())

    # API æ¸¬è©¦ï¼ˆéœ€è¦å¾Œç«¯é‹è¡Œï¼‰
    if run_api or run_all:
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        results.append(loop.run_until_complete(test_api_endpoints()))

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ç¸½çµå ±å‘Š
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\n" + "=" * 60)
    print("ğŸ“Š æ¸¬è©¦ç¸½çµå ±å‘Š")
    print("=" * 60)

    total_passed = sum(r.passed for r in results)
    total_failed = sum(r.failed for r in results)
    total = total_passed + total_failed

    for r in results:
        status = "âœ…" if r.failed == 0 else "âŒ"
        print(f"  {status} {r.name:25s} | {r.passed}/{r.passed + r.failed} é€šé")
        for err in r.errors:
            print(f"     âš ï¸  {err}")

    print(f"\n  ç¸½è¨ˆ: {total_passed}/{total} é€šé | {total_failed} å¤±æ•—")

    if total_failed == 0:
        print("\n  ğŸ‰ å…¨éƒ¨æ¸¬è©¦é€šéï¼AI å¼•æ“åŠŸèƒ½å®Œæ•´æ€§ç¢ºèªï¼")
        return 0
    else:
        print(f"\n  âš ï¸  æœ‰ {total_failed} é …æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ä¸Šæ–¹éŒ¯èª¤è¨Šæ¯")
        return 1


if __name__ == "__main__":
    sys.exit(main())
